{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex5/octave/libs/linearRegCostFn.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/linearRegCostFn.m\n",
    "function J = linearRegCostFn(X, y, theta, lambda)\n",
    "    m = length(y);\n",
    "    J = 0;\n",
    "\n",
    "    error = X * theta - y;\n",
    "    J = (error' * error) / (2*m);\n",
    "    v = theta;\n",
    "    v(1) = 0;\n",
    "\n",
    "    reg = (lambda/(2*m)) * (v' * v);\n",
    "    J = J + reg;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex5/octave/libs/linearRegGradFn.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/linearRegGradFn.m\n",
    "function grad = linearRegGradFn(X, y, theta, lambda)\n",
    "    m = length(y);\n",
    "    grad = zeros(size(theta));\n",
    "\n",
    "    v = theta;\n",
    "    v(1) = 0;\n",
    "\n",
    "    grad = ((X * theta - y)' * X)' / m;\n",
    "    reg = (lambda / m) * v;\n",
    "    grad = grad + reg;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex5/octave/libs/linearRegCostNGradFunction.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/linearRegCostNGradFunction.m\n",
    "function [J, grad] = linearRegCostNGradFunction(X, y, theta, lambda)\n",
    "    J = linearRegCostFn(X, y, theta, lambda);\n",
    "    grad = linearRegGradFn(X, y, theta, lambda);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex5/octave/libs/trainLinearReg.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/trainLinearReg.m\n",
    "function [theta] = trainLinearReg(X, y, lambda)\n",
    "    initial_theta = zeros(size(X, 2), 1);\n",
    "    costFn = @(t) linearRegCostNGradFunction(X, y, t, lambda);\n",
    "    options = optimset('MaxIter', 200, 'GradObj', 'on');\n",
    "    theta = fmincg(costFn, initial_theta, options);\n",
    "    % theta = fminunc(costFn, initial_theta, options);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex5/octave/libs/learningCurve.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/learningCurve.m\n",
    "function [error_train, error_val] = learningCurve(X, y, Xval, yval, lambda)\n",
    "    m = size(X, 1);\n",
    "    error_train = zeros(m, 1);\n",
    "    error_val = zeros(m, 1);\n",
    "\n",
    "    for i = 1:m\n",
    "        theta = trainLinearReg(X(1:i, :), y(1:i), lambda);\n",
    "        error_train(i) = linearRegCostFn(X(1:i, :), y(1:i), theta, 0);\n",
    "        error_val(i) = linearRegCostFn(Xval, yval, theta, 0);\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex5/octave/libs/RndlearningCurve.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/RndlearningCurve.m\n",
    "function [error_train, error_val] = RndlearningCurve(X, y, Xval, yval, lambda)\n",
    "    m = size(X, 1);\n",
    "    error_train = zeros(m, 1);\n",
    "    error_val = zeros(m, 1);\n",
    "\n",
    "    for i = 1:m\n",
    "        error_sample_train = zeros(i, 1);\n",
    "        error_sample_val = zeros(i, 1);\n",
    "        for j=1:m/i\n",
    "            train_seq = randperm(m, i);\n",
    "            theta = trainLinearReg(X(train_seq, :), y(train_seq), lambda);\n",
    "            error_sample_train(i) = linearRegCostFn(X(train_seq, :), y(train_seq), theta, 0);\n",
    "            error_sample_val(i) = linearRegCostFn(Xval, yval, theta, 0);\n",
    "        end\n",
    "        error_train(i) = mean(error_sample_train);\n",
    "        error_val(i) = mean(error_sample_val);\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex5/octave/libs/polyFeatures.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/polyFeatures.m\n",
    "function [X_poly] = polyFeatures(X, p)\n",
    "    m = size(X, 1);\n",
    "    X_poly = zeros(m, p);\n",
    "\n",
    "    for i = 1:p\n",
    "        X_poly(:, i) = X(:, 1) .^ i;\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex5/octave/libs/featureNormalize.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/featureNormalize.m\n",
    "function [X_norm, mu, sigma] = featureNormalize(X)\n",
    "    mu = mean(X);\n",
    "    X_norm = bsxfun(@minus, X, mu);\n",
    "\n",
    "    sigma = std(X_norm);\n",
    "    X_norm = bsxfun(@rdivide, X_norm, sigma);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex5/octave/libs/plotFit.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/plotFit.m\n",
    "function plotFit(min_x, max_x, mu, sigma, theta, p)\n",
    "    hold on;\n",
    "\n",
    "    x = (min_x - 15: 0.05 : max_x + 25)';\n",
    "    X_poly = polyFeatures(x, p);\n",
    "    X_poly = bsxfun(@minus, X_poly, mu);\n",
    "    X_poly = bsxfun(@rdivide, X_poly, sigma);\n",
    "    X_poly = [ones(size(x, 1), 1) X_poly];\n",
    "\n",
    "    plot(x, X_poly * theta, '--', 'LineWidth', 2);\n",
    "\n",
    "    hold off;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex5/octave/libs/validationCurve.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/validationCurve.m\n",
    "function [lambda_vec, error_train, error_val] = validationCurve(X, y, Xval, yval)\n",
    "    lambda_vec = [0 0.001 0.003 0.01 0.03 0.1 0.3 1 3 10]';\n",
    "\n",
    "    error_train = zeros(length(lambda_vec), 1);\n",
    "    error_val = zeros(length(lambda_vec), 1);\n",
    "\n",
    "    for i = 1:length(lambda_vec)\n",
    "        lambda = lambda_vec(i);\n",
    "        theta = trainLinearReg(X, y, lambda);\n",
    "        error_train(i) = linearRegCostFn(X, y, theta, 0);\n",
    "        error_val(i) = linearRegCostFn(Xval, yval, theta, 0);\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex5/octave/libs/fmincg.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/fmincg.m\n",
    "function [X, fX, i] = fmincg(f, X, options, P1, P2, P3, P4, P5)\n",
    "    % Minimize a continuous differentialble multivariate function. Starting point\n",
    "    % is given by \"X\" (D by 1), and the function named in the string \"f\", must\n",
    "    % return a function value and a vector of partial derivatives. The Polack-\n",
    "    % Ribiere flavour of conjugate gradients is used to compute search directions,\n",
    "    % and a line search using quadratic and cubic polynomial approximations and the\n",
    "    % Wolfe-Powell stopping criteria is used together with the slope ratio method\n",
    "    % for guessing initial step sizes. Additionally a bunch of checks are made to\n",
    "    % make sure that exploration is taking place and that extrapolation will not\n",
    "    % be unboundedly large. The \"length\" gives the length of the run: if it is\n",
    "    % positive, it gives the maximum number of line searches, if negative its\n",
    "    % absolute gives the maximum allowed number of function evaluations. You can\n",
    "    % (optionally) give \"length\" a second component, which will indicate the\n",
    "    % reduction in function value to be expected in the first line-search (defaults\n",
    "    % to 1.0). The function returns when either its length is up, or if no further\n",
    "    % progress can be made (ie, we are at a minimum, or so close that due to\n",
    "    % numerical problems, we cannot get any closer). If the function terminates\n",
    "    % within a few iterations, it could be an indication that the function value\n",
    "    % and derivatives are not consistent (ie, there may be a bug in the\n",
    "    % implementation of your \"f\" function). The function returns the found\n",
    "    % solution \"X\", a vector of function values \"fX\" indicating the progress made\n",
    "    % and \"i\" the number of iterations (line searches or function evaluations,\n",
    "    % depending on the sign of \"length\") used.\n",
    "    %\n",
    "    % Usage: [X, fX, i] = fmincg(f, X, options, P1, P2, P3, P4, P5)\n",
    "    %\n",
    "    % See also: checkgrad \n",
    "    %\n",
    "    % Copyright (C) 2001 and 2002 by Carl Edward Rasmussen. Date 2002-02-13\n",
    "    %\n",
    "    %\n",
    "    % (C) Copyright 1999, 2000 & 2001, Carl Edward Rasmussen\n",
    "    % \n",
    "    % Permission is granted for anyone to copy, use, or modify these\n",
    "    % programs and accompanying documents for purposes of research or\n",
    "    % education, provided this copyright notice is retained, and note is\n",
    "    % made of any changes that have been made.\n",
    "    % \n",
    "    % These programs and documents are distributed without any warranty,\n",
    "    % express or implied.  As the programs were written for research\n",
    "    % purposes only, they have not been tested to the degree that would be\n",
    "    % advisable in any important application.  All use of these programs is\n",
    "    % entirely at the user's own risk.\n",
    "    %\n",
    "    % [ml-class] Changes Made:\n",
    "    % 1) Function name and argument specifications\n",
    "    % 2) Output display\n",
    "    %\n",
    "\n",
    "    % Read options\n",
    "    if exist('options', 'var') && ~isempty(options) && isfield(options, 'MaxIter')\n",
    "        length = options.MaxIter;\n",
    "    else\n",
    "        length = 100;\n",
    "    end\n",
    "\n",
    "\n",
    "    RHO = 0.01;                            % a bunch of constants for line searches\n",
    "    SIG = 0.5;       % RHO and SIG are the constants in the Wolfe-Powell conditions\n",
    "    INT = 0.1;    % don't reevaluate within 0.1 of the limit of the current bracket\n",
    "    EXT = 3.0;                    % extrapolate maximum 3 times the current bracket\n",
    "    MAX = 20;                         % max 20 function evaluations per line search\n",
    "    RATIO = 100;                                      % maximum allowed slope ratio\n",
    "\n",
    "    argstr = ['feval(f, X'];                      % compose string used to call function\n",
    "    for i = 1:(nargin - 3)\n",
    "        argstr = [argstr, ',P', int2str(i)];\n",
    "    end\n",
    "    argstr = [argstr, ')'];\n",
    "\n",
    "    if max(size(length)) == 2, red=length(2); length=length(1); else red=1; end\n",
    "    S=['Iteration '];\n",
    "\n",
    "    i = 0;                                            % zero the run length counter\n",
    "    ls_failed = 0;                             % no previous line search has failed\n",
    "    fX = [];\n",
    "    [f1 df1] = eval(argstr);                      % get function value and gradient\n",
    "    i = i + (length<0);                                            % count epochs?!\n",
    "    s = -df1;                                        % search direction is steepest\n",
    "    d1 = -s'*s;                                                 % this is the slope\n",
    "    z1 = red/(1-d1);                                  % initial step is red/(|s|+1)\n",
    "\n",
    "    while i < abs(length)                                      % while not finished\n",
    "        i = i + (length>0);                                      % count iterations?!\n",
    "\n",
    "        X0 = X; f0 = f1; df0 = df1;                   % make a copy of current values\n",
    "        X = X + z1*s;                                             % begin line search\n",
    "        [f2 df2] = eval(argstr);\n",
    "        i = i + (length<0);                                          % count epochs?!\n",
    "        d2 = df2'*s;\n",
    "        f3 = f1; d3 = d1; z3 = -z1;             % initialize point 3 equal to point 1\n",
    "        if length>0, M = MAX; else M = min(MAX, -length-i); end\n",
    "        success = 0; limit = -1;                     % initialize quanteties\n",
    "        while 1\n",
    "            while ((f2 > f1+z1*RHO*d1) || (d2 > -SIG*d1)) && (M > 0) \n",
    "                limit = z1;                                         % tighten the bracket\n",
    "                if f2 > f1\n",
    "                  z2 = z3 - (0.5*d3*z3*z3)/(d3*z3+f2-f3);                 % quadratic fit\n",
    "                else\n",
    "                  A = 6*(f2-f3)/z3+3*(d2+d3);                                 % cubic fit\n",
    "                  B = 3*(f3-f2)-z3*(d3+2*d2);\n",
    "                  z2 = (sqrt(B*B-A*d2*z3*z3)-B)/A;       % numerical error possible - ok!\n",
    "                end\n",
    "                if isnan(z2) || isinf(z2)\n",
    "                  z2 = z3/2;                  % if we had a numerical problem then bisect\n",
    "                end\n",
    "                z2 = max(min(z2, INT*z3),(1-INT)*z3);  % don't accept too close to limits\n",
    "                z1 = z1 + z2;                                           % update the step\n",
    "                X = X + z2*s;\n",
    "                [f2 df2] = eval(argstr);\n",
    "                M = M - 1; i = i + (length<0);                           % count epochs?!\n",
    "                d2 = df2'*s;\n",
    "                z3 = z3-z2;                    % z3 is now relative to the location of z2\n",
    "            end\n",
    "            if f2 > f1+z1*RHO*d1 || d2 > -SIG*d1\n",
    "                break;                                                % this is a failure\n",
    "            elseif d2 > SIG*d1\n",
    "                success = 1; break;                                             % success\n",
    "            elseif M == 0\n",
    "                break;                                                          % failure\n",
    "            end\n",
    "            A = 6*(f2-f3)/z3+3*(d2+d3);                      % make cubic extrapolation\n",
    "            B = 3*(f3-f2)-z3*(d3+2*d2);\n",
    "            z2 = -d2*z3*z3/(B+sqrt(B*B-A*d2*z3*z3));        % num. error possible - ok!\n",
    "            if ~isreal(z2) || isnan(z2) || isinf(z2) || z2 < 0   % num prob or wrong sign?\n",
    "                if limit < -0.5                               % if we have no upper limit\n",
    "                    z2 = z1 * (EXT-1);                 % the extrapolate the maximum amount\n",
    "                else\n",
    "                    z2 = (limit-z1)/2;                                   % otherwise bisect\n",
    "                end\n",
    "            elseif (limit > -0.5) && (z2+z1 > limit)          % extraplation beyond max?\n",
    "                z2 = (limit-z1)/2;                                               % bisect\n",
    "            elseif (limit < -0.5) && (z2+z1 > z1*EXT)       % extrapolation beyond limit\n",
    "                z2 = z1*(EXT-1.0);                           % set to extrapolation limit\n",
    "            elseif z2 < -z3*INT\n",
    "                z2 = -z3*INT;\n",
    "            elseif (limit > -0.5) && (z2 < (limit-z1)*(1.0-INT))   % too close to limit?\n",
    "                z2 = (limit-z1)*(1.0-INT);\n",
    "            end\n",
    "            f3 = f2; d3 = d2; z3 = -z2;                  % set point 3 equal to point 2\n",
    "            z1 = z1 + z2; X = X + z2*s;                      % update current estimates\n",
    "            [f2 df2] = eval(argstr);\n",
    "            M = M - 1; i = i + (length<0);                             % count epochs?!\n",
    "            d2 = df2'*s;\n",
    "        end                                                      % end of line search\n",
    "\n",
    "        if success                                         % if line search succeeded\n",
    "            f1 = f2; fX = [fX' f1]';\n",
    "            fprintf('%s %4i | Cost: %4.6e\\r', S, i, f1);\n",
    "            s = (df2'*df2-df1'*df2)/(df1'*df1)*s - df2;      % Polack-Ribiere direction\n",
    "            tmp = df1; df1 = df2; df2 = tmp;                         % swap derivatives\n",
    "            d2 = df1'*s;\n",
    "            if d2 > 0                                      % new slope must be negative\n",
    "                s = -df1;                              % otherwise use steepest direction\n",
    "                d2 = -s'*s;    \n",
    "            end\n",
    "            z1 = z1 * min(RATIO, d1/(d2-realmin));          % slope ratio but max RATIO\n",
    "            d1 = d2;\n",
    "            ls_failed = 0;                              % this line search did not fail\n",
    "        else\n",
    "          X = X0; f1 = f0; df1 = df0;  % restore point from before failed line search\n",
    "          if ls_failed || i > abs(length)          % line search failed twice in a row\n",
    "              break;                             % or we ran out of time, so we give up\n",
    "          end\n",
    "          tmp = df1; df1 = df2; df2 = tmp;                         % swap derivatives\n",
    "          s = -df1;                                                    % try steepest\n",
    "          d1 = -s'*s;\n",
    "          z1 = 1/(1-d1);                     \n",
    "          ls_failed = 1;                                    % this line search failed\n",
    "        end\n",
    "        if exist('OCTAVE_VERSION')\n",
    "            fflush(stdout);\n",
    "        end\n",
    "      end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "7.1.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78085f80e15a7736ac1017358e79479ec892a173a5f11cd4b2f9ba4c9c3f203b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
