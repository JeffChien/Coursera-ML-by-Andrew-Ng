{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex8/octave/libs/estimateGaussian.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/estimateGaussian.m\n",
    "function [mu, sigma2] = estimateGaussian(X)\n",
    "    [m, n] = size(X);\n",
    "\n",
    "    mu = zeros(n, 1);\n",
    "    sigma2 = zeros(n, 1);\n",
    "\n",
    "    mu = (sum(X) ./ m)';\n",
    "    sigma2 = (sum((X - mu') .^ 2) ./ m)';\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex8/octave/libs/estimateGaussianDensity.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/estimateGaussianDensity.m\n",
    "function p = estimateGaussianDensity(X, mu, sigma2)\n",
    "    n = length(mu);\n",
    "    X = X - mu';\n",
    "    p = prod((2*pi)^(-0.5)*(sigma2').^(-0.5) .* exp(-0.5*(X .* X)./sigma2'), 2);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex8/octave/libs/multivariateGaussian.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/multivariateGaussian.m\n",
    "function p = multivariateGaussian(X, mu, sigma2)\n",
    "    n = length(mu);\n",
    "    if(size(sigma2, 2) == 1 || size(sigma, 1) == 1)\n",
    "        Sigma2 = diag(sigma2);\n",
    "    end\n",
    "\n",
    "    X = X - mu';\n",
    "    p = (2 * pi)^(-n/2) * det(Sigma2)^(-0.5) * exp(-0.5*sum(X*pinv(Sigma2) .* X, 2));\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex8/octave/libs/visualizeFit.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/visualizeFit.m\n",
    "function visualizeFit(X, mu, sigma2, density_fn)\n",
    "\n",
    "    [X1, X2] = meshgrid(0:.5:35);\n",
    "\n",
    "    Z = density_fn([X1(:) X2(:)], mu, sigma2);\n",
    "    Z = reshape(Z, size(X1));\n",
    "\n",
    "    plot(X(:, 1), X(:, 2), 'bx');\n",
    "    hold on;\n",
    "    if (sum(isinf(Z)) == 0)\n",
    "        contour(X1, X2, Z, 10 .^(-20:3:0)');\n",
    "    end\n",
    "    hold off;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex8/octave/libs/selectThreshold.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/selectThreshold.m\n",
    "function [bestEpsilon bestF1] = selectThreshold(yval, pval)\n",
    "\n",
    "    bestEpsilon = 0;\n",
    "    bestF1 = 0;\n",
    "    F1 = 0;\n",
    "\n",
    "    stepsize = (max(pval) - min(pval)) / 1000;\n",
    "    for epsilon = min(pval):stepsize:max(pval)\n",
    "        pred = pval < epsilon;\n",
    "        tp = sum((pred == 1) & (yval == 1));\n",
    "        fp = sum((pred == 1) & (yval == 0));\n",
    "        fn = sum((pred == 0) & (yval == 1));\n",
    "        prec = tp / (tp + fp);\n",
    "        rec = tp / (tp + fn);\n",
    "        F1 = (2 * prec * rec) / (prec + rec);\n",
    "\n",
    "        if F1 > bestF1\n",
    "            bestF1 = F1;\n",
    "            bestEpsilon = epsilon;\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex8/octave/libs/plotFeatureHist.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/plotFeatureHist.m\n",
    "function plotFeatureHist(X, ncols=3, nbins=25)\n",
    "    nfeatures = size(X, 2);\n",
    "    ncols = min(nfeatures, ncols);\n",
    "    nrows = ceil(nfeatures / ncols);\n",
    "    for i = 1:nfeatures\n",
    "        subplot(nrows, ncols, i);\n",
    "        hist(X(:, i), nbins);\n",
    "        title(sprintf('feature x%d', i));\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex8/octave/libs/cofiCostFn.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/cofiCostFn.m\n",
    "function J = cofiCostFn(X, Theta, Y, R, lambda)\n",
    "    % X = m x n\n",
    "    % Theta = u x n\n",
    "    % Y = m x u\n",
    "    % R = m x u\n",
    "    J = 0.5 * sum(sum(((X * Theta' - Y) .^ 2) .* R));\n",
    "\n",
    "    % reg\n",
    "    reg = 0.5 * lambda * (sum(sum(Theta .^2)) + sum(sum(X .^2)));\n",
    "\n",
    "    J += reg;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex8/octave/libs/cofiGradFn.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/cofiGradFn.m\n",
    "function grad = cofiGradFn(X, Theta, Y, R, lambda)\n",
    "    % X = m x n\n",
    "    % Theta = u x n\n",
    "    % Y = m x u\n",
    "    % R = m x u\n",
    "\n",
    "    X_grad = zeros(size(X));\n",
    "    Theta_grad = zeros(size(Theta));\n",
    "\n",
    "    common = (X * Theta' - Y) .* R;\n",
    "\n",
    "    X_grad = common * Theta + lambda * X;\n",
    "    Theta_grad = common' * X + lambda * Theta;\n",
    "\n",
    "    grad = [X_grad(:); Theta_grad(:)];\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex8/octave/libs/cofiCostnGradFn.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/cofiCostnGradFn.m\n",
    "function [J, grad] = cofiCostnGradFn(params, Y, R, num_users, num_movies, num_features, lambda)\n",
    "    X = reshape(params(1:num_movies*num_features), num_movies, num_features);\n",
    "    Theta = reshape(params(num_movies*num_features+1:end), num_users, num_features);\n",
    "\n",
    "    J = 0;\n",
    "    X_grad = zeros(size(X));\n",
    "    Theta_grad = zeros(size(Theta));\n",
    "\n",
    "    J = cofiCostFn(X, Theta, Y, R, lambda);\n",
    "    grad = cofiGradFn(X, Theta, Y, R, lambda);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex8/octave/libs/normalizeRatings.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/normalizeRatings.m\n",
    "function [Ynorm, Ymean] = normalizeRatings(Y, R)\n",
    "    [m, n] = size(Y);\n",
    "    Ymean = zeros(m, 1);\n",
    "    Ynorm = zeros(size(Y));\n",
    "    for i = 1:m\n",
    "        idx = find(R(i, :) == 1);\n",
    "        Ymean(i) = mean(Y(i, idx));\n",
    "        Ynorm(i, idx) = Y(i, idx) - Ymean(i);\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex8/octave/libs/topkRelatedMovie.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/topkRelatedMovie.m\n",
    "function ix = topkRelatedMovies(X, mi, k)\n",
    "    m = size(X, 1);\n",
    "    xi = X(mi, :);\n",
    "\n",
    "    error = sum((X - xi) .^2, 2);\n",
    "    [r, ix] = sort(error);\n",
    "    ix = ix(2:k+1);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex8/octave/libs/loadMovieList.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/loadMovieList.m\n",
    "function movieList = loadMovieList()\n",
    "    fd = fopen('../../data/movie_ids.txt');\n",
    "    n = 1682;\n",
    "    movieList = cell(n, 1);\n",
    "    for i = 1:n\n",
    "        line = fgets(fd);\n",
    "        [idx, movieName] = strtok(line, ' ');\n",
    "        movieList{i} = strtrim(movieName);\n",
    "    end\n",
    "    fclose(fd);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex8/octave/libs/computeNumericalGradient.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/computeNumericalGradient.m\n",
    "function numgrad = computeNumericalGradient(J, theta)\n",
    "    numgrad = zeros(size(theta));\n",
    "    perturb = zeros(size(theta));\n",
    "    e = 1e-4;\n",
    "\n",
    "    for p = 1:numel(theta)\n",
    "        perturb(p) = e;\n",
    "        loss1 = J(theta - perturb);\n",
    "        loss2 = J(theta + perturb);\n",
    "\n",
    "        numgrad(p) = (loss2 - loss1) / (2*e);\n",
    "        perturb(p) = 0;\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex8/octave/libs/checkCostFunction.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/checkCostFunction.m\n",
    "function checkCostFunction(lambda=0)\n",
    "\n",
    "    X_t = rand(4, 3);\n",
    "    Theta_t = rand(5, 3);\n",
    "\n",
    "    Y = X_t * Theta_t';\n",
    "    Y(rand(size(Y)) > 0.5) = 0;\n",
    "    R = zeros(size(Y));\n",
    "    R(Y ~= 0) = 1;\n",
    "\n",
    "    % run gradient checking\n",
    "    X = randn(size(X_t));\n",
    "    Theta = randn(size(Theta_t));\n",
    "    num_users = size(Y, 2);\n",
    "    num_movies = size(Y, 1);\n",
    "    num_features = size(Theta_t, 2);\n",
    "\n",
    "    numgrad = computeNumericalGradient(...\n",
    "                @(t) cofiCostnGradFn(t, Y, R, num_users, num_movies, num_features, lambda), ...\n",
    "                [X(:); Theta(:)]);\n",
    "    [cost, grad] = cofiCostnGradFn([X(:); Theta(:)], Y, R, num_users, num_movies, num_features, lambda);\n",
    "    disp([numgrad grad]);\n",
    "    fprintf(['The above two columns you get should be very similar.\\n' ...\n",
    "            '(Left-Your Numerical Gradient, Right-Analytical Gradient)\\n\\n']);\n",
    "\n",
    "    diff = norm(numgrad-grad)/norm(numgrad+grad);\n",
    "    fprintf(['If your backpropagation implementation is correct, then \\n' ...\n",
    "            'the relative difference will be small (less than 1e-9). \\n' ...\n",
    "            '\\nRelative Difference: %g\\n'], diff);\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jchien/workspace/courses/coursera_ml/ex8/octave/libs/fmincg.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file ../libs/fmincg.m\n",
    "function [X, fX, i] = fmincg(f, X, options, P1, P2, P3, P4, P5)\n",
    "    % Minimize a continuous differentialble multivariate function. Starting point\n",
    "    % is given by \"X\" (D by 1), and the function named in the string \"f\", must\n",
    "    % return a function value and a vector of partial derivatives. The Polack-\n",
    "    % Ribiere flavour of conjugate gradients is used to compute search directions,\n",
    "    % and a line search using quadratic and cubic polynomial approximations and the\n",
    "    % Wolfe-Powell stopping criteria is used together with the slope ratio method\n",
    "    % for guessing initial step sizes. Additionally a bunch of checks are made to\n",
    "    % make sure that exploration is taking place and that extrapolation will not\n",
    "    % be unboundedly large. The \"length\" gives the length of the run: if it is\n",
    "    % positive, it gives the maximum number of line searches, if negative its\n",
    "    % absolute gives the maximum allowed number of function evaluations. You can\n",
    "    % (optionally) give \"length\" a second component, which will indicate the\n",
    "    % reduction in function value to be expected in the first line-search (defaults\n",
    "    % to 1.0). The function returns when either its length is up, or if no further\n",
    "    % progress can be made (ie, we are at a minimum, or so close that due to\n",
    "    % numerical problems, we cannot get any closer). If the function terminates\n",
    "    % within a few iterations, it could be an indication that the function value\n",
    "    % and derivatives are not consistent (ie, there may be a bug in the\n",
    "    % implementation of your \"f\" function). The function returns the found\n",
    "    % solution \"X\", a vector of function values \"fX\" indicating the progress made\n",
    "    % and \"i\" the number of iterations (line searches or function evaluations,\n",
    "    % depending on the sign of \"length\") used.\n",
    "    %\n",
    "    % Usage: [X, fX, i] = fmincg(f, X, options, P1, P2, P3, P4, P5)\n",
    "    %\n",
    "    % See also: checkgrad \n",
    "    %\n",
    "    % Copyright (C) 2001 and 2002 by Carl Edward Rasmussen. Date 2002-02-13\n",
    "    %\n",
    "    %\n",
    "    % (C) Copyright 1999, 2000 & 2001, Carl Edward Rasmussen\n",
    "    % \n",
    "    % Permission is granted for anyone to copy, use, or modify these\n",
    "    % programs and accompanying documents for purposes of research or\n",
    "    % education, provided this copyright notice is retained, and note is\n",
    "    % made of any changes that have been made.\n",
    "    % \n",
    "    % These programs and documents are distributed without any warranty,\n",
    "    % express or implied.  As the programs were written for research\n",
    "    % purposes only, they have not been tested to the degree that would be\n",
    "    % advisable in any important application.  All use of these programs is\n",
    "    % entirely at the user's own risk.\n",
    "    %\n",
    "    % [ml-class] Changes Made:\n",
    "    % 1) Function name and argument specifications\n",
    "    % 2) Output display\n",
    "    %\n",
    "\n",
    "    % Read options\n",
    "    if exist('options', 'var') && ~isempty(options) && isfield(options, 'MaxIter')\n",
    "        length = options.MaxIter;\n",
    "    else\n",
    "        length = 100;\n",
    "    end\n",
    "\n",
    "\n",
    "    RHO = 0.01;                            % a bunch of constants for line searches\n",
    "    SIG = 0.5;       % RHO and SIG are the constants in the Wolfe-Powell conditions\n",
    "    INT = 0.1;    % don't reevaluate within 0.1 of the limit of the current bracket\n",
    "    EXT = 3.0;                    % extrapolate maximum 3 times the current bracket\n",
    "    MAX = 20;                         % max 20 function evaluations per line search\n",
    "    RATIO = 100;                                      % maximum allowed slope ratio\n",
    "\n",
    "    argstr = ['feval(f, X'];                      % compose string used to call function\n",
    "    for i = 1:(nargin - 3)\n",
    "        argstr = [argstr, ',P', int2str(i)];\n",
    "    end\n",
    "    argstr = [argstr, ')'];\n",
    "\n",
    "    if max(size(length)) == 2, red=length(2); length=length(1); else red=1; end\n",
    "    S=['Iteration '];\n",
    "\n",
    "    i = 0;                                            % zero the run length counter\n",
    "    ls_failed = 0;                             % no previous line search has failed\n",
    "    fX = [];\n",
    "    [f1 df1] = eval(argstr);                      % get function value and gradient\n",
    "    i = i + (length<0);                                            % count epochs?!\n",
    "    s = -df1;                                        % search direction is steepest\n",
    "    d1 = -s'*s;                                                 % this is the slope\n",
    "    z1 = red/(1-d1);                                  % initial step is red/(|s|+1)\n",
    "\n",
    "    while i < abs(length)                                      % while not finished\n",
    "        i = i + (length>0);                                      % count iterations?!\n",
    "\n",
    "        X0 = X; f0 = f1; df0 = df1;                   % make a copy of current values\n",
    "        X = X + z1*s;                                             % begin line search\n",
    "        [f2 df2] = eval(argstr);\n",
    "        i = i + (length<0);                                          % count epochs?!\n",
    "        d2 = df2'*s;\n",
    "        f3 = f1; d3 = d1; z3 = -z1;             % initialize point 3 equal to point 1\n",
    "        if length>0, M = MAX; else M = min(MAX, -length-i); end\n",
    "        success = 0; limit = -1;                     % initialize quanteties\n",
    "        while 1\n",
    "            while ((f2 > f1+z1*RHO*d1) || (d2 > -SIG*d1)) && (M > 0) \n",
    "                limit = z1;                                         % tighten the bracket\n",
    "                if f2 > f1\n",
    "                  z2 = z3 - (0.5*d3*z3*z3)/(d3*z3+f2-f3);                 % quadratic fit\n",
    "                else\n",
    "                  A = 6*(f2-f3)/z3+3*(d2+d3);                                 % cubic fit\n",
    "                  B = 3*(f3-f2)-z3*(d3+2*d2);\n",
    "                  z2 = (sqrt(B*B-A*d2*z3*z3)-B)/A;       % numerical error possible - ok!\n",
    "                end\n",
    "                if isnan(z2) || isinf(z2)\n",
    "                  z2 = z3/2;                  % if we had a numerical problem then bisect\n",
    "                end\n",
    "                z2 = max(min(z2, INT*z3),(1-INT)*z3);  % don't accept too close to limits\n",
    "                z1 = z1 + z2;                                           % update the step\n",
    "                X = X + z2*s;\n",
    "                [f2 df2] = eval(argstr);\n",
    "                M = M - 1; i = i + (length<0);                           % count epochs?!\n",
    "                d2 = df2'*s;\n",
    "                z3 = z3-z2;                    % z3 is now relative to the location of z2\n",
    "            end\n",
    "            if f2 > f1+z1*RHO*d1 || d2 > -SIG*d1\n",
    "                break;                                                % this is a failure\n",
    "            elseif d2 > SIG*d1\n",
    "                success = 1; break;                                             % success\n",
    "            elseif M == 0\n",
    "                break;                                                          % failure\n",
    "            end\n",
    "            A = 6*(f2-f3)/z3+3*(d2+d3);                      % make cubic extrapolation\n",
    "            B = 3*(f3-f2)-z3*(d3+2*d2);\n",
    "            z2 = -d2*z3*z3/(B+sqrt(B*B-A*d2*z3*z3));        % num. error possible - ok!\n",
    "            if ~isreal(z2) || isnan(z2) || isinf(z2) || z2 < 0   % num prob or wrong sign?\n",
    "                if limit < -0.5                               % if we have no upper limit\n",
    "                    z2 = z1 * (EXT-1);                 % the extrapolate the maximum amount\n",
    "                else\n",
    "                    z2 = (limit-z1)/2;                                   % otherwise bisect\n",
    "                end\n",
    "            elseif (limit > -0.5) && (z2+z1 > limit)          % extraplation beyond max?\n",
    "                z2 = (limit-z1)/2;                                               % bisect\n",
    "            elseif (limit < -0.5) && (z2+z1 > z1*EXT)       % extrapolation beyond limit\n",
    "                z2 = z1*(EXT-1.0);                           % set to extrapolation limit\n",
    "            elseif z2 < -z3*INT\n",
    "                z2 = -z3*INT;\n",
    "            elseif (limit > -0.5) && (z2 < (limit-z1)*(1.0-INT))   % too close to limit?\n",
    "                z2 = (limit-z1)*(1.0-INT);\n",
    "            end\n",
    "            f3 = f2; d3 = d2; z3 = -z2;                  % set point 3 equal to point 2\n",
    "            z1 = z1 + z2; X = X + z2*s;                      % update current estimates\n",
    "            [f2 df2] = eval(argstr);\n",
    "            M = M - 1; i = i + (length<0);                             % count epochs?!\n",
    "            d2 = df2'*s;\n",
    "        end                                                      % end of line search\n",
    "\n",
    "        if success                                         % if line search succeeded\n",
    "            f1 = f2; fX = [fX' f1]';\n",
    "            fprintf('%s %4i | Cost: %4.6e\\r', S, i, f1);\n",
    "            s = (df2'*df2-df1'*df2)/(df1'*df1)*s - df2;      % Polack-Ribiere direction\n",
    "            tmp = df1; df1 = df2; df2 = tmp;                         % swap derivatives\n",
    "            d2 = df1'*s;\n",
    "            if d2 > 0                                      % new slope must be negative\n",
    "                s = -df1;                              % otherwise use steepest direction\n",
    "                d2 = -s'*s;    \n",
    "            end\n",
    "            z1 = z1 * min(RATIO, d1/(d2-realmin));          % slope ratio but max RATIO\n",
    "            d1 = d2;\n",
    "            ls_failed = 0;                              % this line search did not fail\n",
    "        else\n",
    "          X = X0; f1 = f0; df1 = df0;  % restore point from before failed line search\n",
    "          if ls_failed || i > abs(length)          % line search failed twice in a row\n",
    "              break;                             % or we ran out of time, so we give up\n",
    "          end\n",
    "          tmp = df1; df1 = df2; df2 = tmp;                         % swap derivatives\n",
    "          s = -df1;                                                    % try steepest\n",
    "          d1 = -s'*s;\n",
    "          z1 = 1/(1-d1);                     \n",
    "          ls_failed = 1;                                    % this line search failed\n",
    "        end\n",
    "        if exist('OCTAVE_VERSION')\n",
    "            fflush(stdout);\n",
    "        end\n",
    "      end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "7.1.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78085f80e15a7736ac1017358e79479ec892a173a5f11cd4b2f9ba4c9c3f203b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
